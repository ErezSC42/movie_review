{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from TextCNN import TextCNN\n",
    "import gzip\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Embedder import Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "FILENAME = \"movies.txt\"\n",
    "COLUMNS = [\"productId\",\n",
    "           \"userId\",\n",
    "           \"profileName\",\n",
    "           \"helpfulness\",\n",
    "           \"score\",\n",
    "           \"time\",\n",
    "           \"summary\",\n",
    "           \"text\"]\n",
    "COL_NUM = 8\n",
    "REVIEW_NUM = 25000\n",
    "PADDED_LEN = 200\n",
    "GLOVE_BINARY_PATH = \"glove.6B.50d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILENAME,\n",
    "                 header=None,\n",
    "                 delimiter=\"\\n\",\n",
    "                 error_bad_lines=False,\n",
    "                 skip_blank_lines=True,\n",
    "                 encoding=\"latin-1\",\n",
    "                 nrows=COL_NUM*REVIEW_NUM)\n",
    "df = pd.DataFrame(np.reshape(df.values,(REVIEW_NUM,COL_NUM)),columns=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"productId\"] = df[\"productId\"].str.replace(\"product/productId:\",\"\")\n",
    "for col in COLUMNS[1:]:\n",
    "    df[col] = df[col].str.replace(\"review/\" + col + \":\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>userId</th>\n",
       "      <th>profileName</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B003AI2VGA</td>\n",
       "      <td>A141HP4LYPWMSR</td>\n",
       "      <td>Brian E. Erland \"Rainbow Sphinx\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1182729600</td>\n",
       "      <td>\"There Is So Much Darkness Now ~ Come For The...</td>\n",
       "      <td>Synopsis: On the daily trek from Juarez, Mexi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B003AI2VGA</td>\n",
       "      <td>A328S9RN3U5M68</td>\n",
       "      <td>Grady Harp</td>\n",
       "      <td>4/4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1181952000</td>\n",
       "      <td>Worthwhile and Important Story Hampered by Po...</td>\n",
       "      <td>THE VIRGIN OF JUAREZ is based on true events ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B003AI2VGA</td>\n",
       "      <td>A1I7QGUDP043DG</td>\n",
       "      <td>Chrissy K. McVay \"Writer\"</td>\n",
       "      <td>8/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1164844800</td>\n",
       "      <td>This movie needed to be made.</td>\n",
       "      <td>The scenes in this film can be very disquieti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B003AI2VGA</td>\n",
       "      <td>A1M5405JH9THP9</td>\n",
       "      <td>golgotha.gov</td>\n",
       "      <td>1/1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1197158400</td>\n",
       "      <td>distantly based on a real tragedy</td>\n",
       "      <td>THE VIRGIN OF JUAREZ (2006)&lt;br /&gt;directed by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B003AI2VGA</td>\n",
       "      <td>ATXL536YX71TR</td>\n",
       "      <td>KerrLines \"&amp;#34;Movies,Music,Theatre&amp;#34;\"</td>\n",
       "      <td>1/1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1188345600</td>\n",
       "      <td>\"What's going on down in Juarez and shining a...</td>\n",
       "      <td>Informationally, this SHOWTIME original is es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     productId           userId                                  profileName  \\\n",
       "0   B003AI2VGA   A141HP4LYPWMSR             Brian E. Erland \"Rainbow Sphinx\"   \n",
       "1   B003AI2VGA   A328S9RN3U5M68                                   Grady Harp   \n",
       "2   B003AI2VGA   A1I7QGUDP043DG                    Chrissy K. McVay \"Writer\"   \n",
       "3   B003AI2VGA   A1M5405JH9THP9                                 golgotha.gov   \n",
       "4   B003AI2VGA    ATXL536YX71TR   KerrLines \"&#34;Movies,Music,Theatre&#34;\"   \n",
       "\n",
       "  helpfulness score         time  \\\n",
       "0         7/7   3.0   1182729600   \n",
       "1         4/4   3.0   1181952000   \n",
       "2        8/10   5.0   1164844800   \n",
       "3         1/1   3.0   1197158400   \n",
       "4         1/1   3.0   1188345600   \n",
       "\n",
       "                                             summary  \\\n",
       "0   \"There Is So Much Darkness Now ~ Come For The...   \n",
       "1   Worthwhile and Important Story Hampered by Po...   \n",
       "2                      This movie needed to be made.   \n",
       "3                  distantly based on a real tragedy   \n",
       "4   \"What's going on down in Juarez and shining a...   \n",
       "\n",
       "                                                text  \n",
       "0   Synopsis: On the daily trek from Juarez, Mexi...  \n",
       "1   THE VIRGIN OF JUAREZ is based on true events ...  \n",
       "2   The scenes in this film can be very disquieti...  \n",
       "3   THE VIRGIN OF JUAREZ (2006)<br />directed by ...  \n",
       "4   Informationally, this SHOWTIME original is es...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep3/text/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = df[\"text\"]\n",
    "y = df[\"score\"].astype(\"float\").astype(\"int\").values.reshape([-1,1])\n",
    "y_one_hot = OneHotEncoder().fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df[\"score\"] == \"review/helpfulness: 0/0\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "embedder = Embedder(None,50,PADDED_LEN,GLOVE_BINARY_PATH)\n",
    "X_embedded = embedder.str_series_to_image(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.025\n",
    "FC_LAYER = 512\n",
    "CLASSES_LEN = 5\n",
    "EMBEDDING_DIM = 50\n",
    "CONV_FILTERS = 128\n",
    "EPOCHS = 50\n",
    "TRAIN_TEST_RATION = 0.2\n",
    "TRAIN_SIZE = (1 - TRAIN_TEST_RATION) * len(X_embedded)\n",
    "TEST_SIZE = (TRAIN_TEST_RATION) * len(X_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_embedded, y_one_hot, test_size=TRAIN_TEST_RATION)\n",
    "X_train = X_train.reshape([-1,1,EMBEDDING_DIM,PADDED_LEN])\n",
    "X_test = X_test.reshape([-1,1,EMBEDDING_DIM,PADDED_LEN])\n",
    "X_train_tensor = torch.Tensor(X_train).to(device)\n",
    "X_test_tensor = torch.Tensor(X_test).to(device)\n",
    "y_train_tensor = torch.Tensor(y_train).long().to(device)\n",
    "y_test_tensor = torch.Tensor(y_test).long().to(device)\n",
    "#y_train_tensor = torch.Tensor(y_train).to(device)\n",
    "#y_test_tensor = torch.Tensor(y_test).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor,y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor,y_test_tensor)\n",
    "trainloader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (conv3): Conv2d(1, 128, kernel_size=(50, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(1, 128, kernel_size=(50, 4), stride=(1, 1))\n",
       "  (conv5): Conv2d(1, 128, kernel_size=(50, 5), stride=(1, 1))\n",
       "  (conv6): Conv2d(1, 128, kernel_size=(50, 8), stride=(1, 1))\n",
       "  (conv7): Conv2d(1, 128, kernel_size=(50, 11), stride=(1, 1))\n",
       "  (conv8): Conv2d(1, 128, kernel_size=(50, 20), stride=(1, 1))\n",
       "  (Avg3_pool): AvgPool2d(kernel_size=(1, 198), stride=(1, 198), padding=0)\n",
       "  (Avg4_pool): AvgPool2d(kernel_size=(1, 197), stride=(1, 197), padding=0)\n",
       "  (Avg5_pool): AvgPool2d(kernel_size=(1, 196), stride=(1, 196), padding=0)\n",
       "  (Avg6_pool): AvgPool2d(kernel_size=(1, 193), stride=(1, 193), padding=0)\n",
       "  (Avg7_pool): AvgPool2d(kernel_size=(1, 190), stride=(1, 190), padding=0)\n",
       "  (Avg8_pool): AvgPool2d(kernel_size=(1, 180), stride=(1, 180), padding=0)\n",
       "  (Max3_pool): MaxPool2d(kernel_size=(1, 198), stride=(1, 198), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Max4_pool): MaxPool2d(kernel_size=(1, 197), stride=(1, 197), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Max5_pool): MaxPool2d(kernel_size=(1, 196), stride=(1, 196), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Max6_pool): MaxPool2d(kernel_size=(1, 193), stride=(1, 193), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Max7_pool): MaxPool2d(kernel_size=(1, 190), stride=(1, 190), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Max8_pool): MaxPool2d(kernel_size=(1, 180), stride=(1, 180), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1536, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout(p=0.3)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout2): Dropout(p=0.3)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout3): Dropout(p=0.3)\n",
       "  (linear1): Linear(in_features=128, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TextCNN(hidden_units=FC_LAYER,\n",
    "                output_len=CLASSES_LEN,\n",
    "                textcnn_filter_count=CONV_FILTERS,\n",
    "                sentence_max_size=PADDED_LEN,\n",
    "                word_embedding_dimension=EMBEDDING_DIM)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-2, weight_decay=1e-5)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_classification(data_loader,model,name):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total = len(data_loader)\n",
    "    testloader.dataset.tensors[0]\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            labels = torch.max(labels, 1)[1]\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the '+name +' reviews: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_mse(data_loader,model,name):\n",
    "    batch_losses = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            batch_losses.append(loss.item())\n",
    "    #print(batch_losses)\n",
    "    mse = np.array(batch_losses).mean()\n",
    "    print('MSE of the network on the '+name +' reviews: %f' % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep3/Desktop/erez_rl/text_review/TextCNN.py:113: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(self.linear1(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 14.999\n",
      "Accuracy of the network on the train reviews: 55 %\n",
      "Accuracy of the network on the test reviews: 54 %\n",
      "[2,    20] loss: 12.359\n",
      "Accuracy of the network on the train reviews: 56 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[3,    20] loss: 12.137\n",
      "Accuracy of the network on the train reviews: 56 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[4,    20] loss: 11.675\n",
      "Accuracy of the network on the train reviews: 57 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[5,    20] loss: 11.019\n",
      "Accuracy of the network on the train reviews: 58 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[6,    20] loss: 10.079\n",
      "Accuracy of the network on the train reviews: 62 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[7,    20] loss: 9.153\n",
      "Accuracy of the network on the train reviews: 65 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[8,    20] loss: 8.163\n",
      "Accuracy of the network on the train reviews: 70 %\n",
      "Accuracy of the network on the test reviews: 54 %\n",
      "[9,    20] loss: 7.476\n",
      "Accuracy of the network on the train reviews: 73 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[10,    20] loss: 6.698\n",
      "Accuracy of the network on the train reviews: 75 %\n",
      "Accuracy of the network on the test reviews: 54 %\n",
      "[11,    20] loss: 6.125\n",
      "Accuracy of the network on the train reviews: 77 %\n",
      "Accuracy of the network on the test reviews: 54 %\n",
      "[12,    20] loss: 5.614\n",
      "Accuracy of the network on the train reviews: 79 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[13,    20] loss: 5.313\n",
      "Accuracy of the network on the train reviews: 80 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[14,    20] loss: 4.886\n",
      "Accuracy of the network on the train reviews: 82 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[15,    20] loss: 4.501\n",
      "Accuracy of the network on the train reviews: 82 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[16,    20] loss: 4.394\n",
      "Accuracy of the network on the train reviews: 83 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[17,    20] loss: 4.325\n",
      "Accuracy of the network on the train reviews: 84 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[18,    20] loss: 3.912\n",
      "Accuracy of the network on the train reviews: 85 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[19,    20] loss: 3.641\n",
      "Accuracy of the network on the train reviews: 87 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[20,    20] loss: 3.482\n",
      "Accuracy of the network on the train reviews: 87 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[21,    20] loss: 3.194\n",
      "Accuracy of the network on the train reviews: 88 %\n",
      "Accuracy of the network on the test reviews: 57 %\n",
      "[22,    20] loss: 3.130\n",
      "Accuracy of the network on the train reviews: 89 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[23,    20] loss: 2.945\n",
      "Accuracy of the network on the train reviews: 89 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[24,    20] loss: 2.817\n",
      "Accuracy of the network on the train reviews: 90 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[25,    20] loss: 2.578\n",
      "Accuracy of the network on the train reviews: 91 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[26,    20] loss: 2.423\n",
      "Accuracy of the network on the train reviews: 90 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[27,    20] loss: 2.706\n",
      "Accuracy of the network on the train reviews: 91 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[28,    20] loss: 2.329\n",
      "Accuracy of the network on the train reviews: 92 %\n",
      "Accuracy of the network on the test reviews: 57 %\n",
      "[29,    20] loss: 1.974\n",
      "Accuracy of the network on the train reviews: 93 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[30,    20] loss: 2.143\n",
      "Accuracy of the network on the train reviews: 91 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[31,    20] loss: 2.182\n",
      "Accuracy of the network on the train reviews: 93 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[32,    20] loss: 1.904\n",
      "Accuracy of the network on the train reviews: 93 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[33,    20] loss: 1.708\n",
      "Accuracy of the network on the train reviews: 93 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[34,    20] loss: 1.724\n",
      "Accuracy of the network on the train reviews: 94 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[35,    20] loss: 1.784\n",
      "Accuracy of the network on the train reviews: 94 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[36,    20] loss: 1.876\n",
      "Accuracy of the network on the train reviews: 93 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[37,    20] loss: 1.706\n",
      "Accuracy of the network on the train reviews: 94 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[38,    20] loss: 1.481\n",
      "Accuracy of the network on the train reviews: 95 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[39,    20] loss: 1.333\n",
      "Accuracy of the network on the train reviews: 95 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[40,    20] loss: 1.320\n",
      "Accuracy of the network on the train reviews: 95 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[41,    20] loss: 1.330\n",
      "Accuracy of the network on the train reviews: 95 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[42,    20] loss: 1.275\n",
      "Accuracy of the network on the train reviews: 96 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[43,    20] loss: 1.300\n",
      "Accuracy of the network on the train reviews: 95 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[44,    20] loss: 1.400\n",
      "Accuracy of the network on the train reviews: 94 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[45,    20] loss: 1.442\n",
      "Accuracy of the network on the train reviews: 95 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[46,    20] loss: 1.443\n",
      "Accuracy of the network on the train reviews: 95 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "[47,    20] loss: 1.221\n",
      "Accuracy of the network on the train reviews: 96 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[48,    20] loss: 0.992\n",
      "Accuracy of the network on the train reviews: 97 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[49,    20] loss: 0.823\n",
      "Accuracy of the network on the train reviews: 97 %\n",
      "Accuracy of the network on the test reviews: 56 %\n",
      "[50,    20] loss: 0.838\n",
      "Accuracy of the network on the train reviews: 97 %\n",
      "Accuracy of the network on the test reviews: 55 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        #loss = criterion(outputs,labels)\n",
    "        loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        #if i % 100 == 0:    # print every 2000 mini-batches\n",
    "    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2))\n",
    "    #print('epoch: [%d] loss: %.3f' % (epoch + 1, running_loss))\n",
    "    check_accuracy_classification(trainloader,model,\"train\")\n",
    "    check_accuracy_classification(testloader,model,\"test\")\n",
    "#     check_accuracy_mse(trainloader,model,\"train\")\n",
    "#     check_accuracy_mse(testloader,model,\"test\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 5000.0 test reviews: 56 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        labels = torch.max(labels, 1)[1]\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the '+ str(TEST_SIZE) +' test reviews: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 20000.0 train reviews: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        labels = torch.max(labels, 1)[1]\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the ' + str(TRAIN_SIZE) + ' train reviews: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 512])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f148ded815f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"the movie was perfect\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPADDED_LEN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/text/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/erez_rl/text_review/TextCNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# project the features to the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/text/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/text/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/text/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1691\u001b[0m             \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected more than 1 value per channel when training, got input size {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m     return torch.batch_norm(\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 512])"
     ]
    }
   ],
   "source": [
    "#review = r\"Informationally, this SHOWTIME original is essential viewing for enlightening audiences on the dangerous plight of women migrant workers from Los Angeles who are routinely and mysteriously murdered on the border between Juarez, Mexico and El Paso, Texas.Since 1993, hundreds of woman have turned up dead and mutilated and no one seems to either care or have an answer. The fear and death continue.<br /><br />Director Kevin Dobson has brought us Michael Fallon's screenplay THE VIRGIN OF JUAREZ to the screen as a fanciful/possible solution to what may be happening down in Juarez.Though this is but a film, the information about the unsolved murders and the religious fanaticism in the area is crucial.<br /><br />Suggested companion film would be AGNES OF GOD.\"\n",
    "review = \"the movie was perfect\"\n",
    "with torch.no_grad():\n",
    "    res = model(torch.Tensor(embedder.str_to_image(review).reshape([1,1,EMBEDDING_DIM,PADDED_LEN])).long().to(device))\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(labels, 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text",
   "language": "python",
   "name": "text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
